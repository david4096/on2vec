{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Graph Completion with on2vec\n",
    "\n",
    "This notebook demonstrates how to use on2vec embeddings for knowledge graph completion tasks. We'll show how to:\n",
    "\n",
    "1. Predict missing subclass relationships in ontologies\n",
    "2. Suggest new object property relations between concepts\n",
    "3. Identify potential concept additions to expand ontologies\n",
    "4. Validate predicted completions using embedding similarity\n",
    "5. Rank completion candidates by confidence scores\n",
    "6. Visualize knowledge graph expansion\n",
    "\n",
    "## Use Case: Ontology Evolution and Curation\n",
    "Ontologies are constantly evolving as new knowledge is discovered. Manual curation is time-consuming and may miss important relationships. Embedding-based completion can suggest new concepts and relations, helping curators identify gaps and expand their knowledge graphs systematically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import networkx as nx\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import umap\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# on2vec imports\n",
    "from on2vec import (\n",
    "    load_embeddings_as_dataframe,\n",
    "    train_ontology_embeddings,\n",
    "    embed_ontology_with_model,\n",
    "    build_graph_from_owl,\n",
    "    build_multi_relation_graph_from_owl\n",
    ")\n",
    "\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Prepare Knowledge Graph and Embeddings\n",
    "\n",
    "Load ontology structure and generate embeddings optimized for completion tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”„ Preparing knowledge graph data for EDAM.owl...\n",
      "  Training completion model...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "train_ontology_embeddings() got an unexpected keyword argument 'text_model_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 99\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ont_file \u001b[38;5;129;01min\u001b[39;00m ontology_files:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(ont_file):\n\u001b[0;32m---> 99\u001b[0m         kg_data \u001b[38;5;241m=\u001b[39m \u001b[43mprepare_knowledge_graph_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mont_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m kg_data:\n\u001b[1;32m    101\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mâœ… Knowledge graph ready:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 20\u001b[0m, in \u001b[0;36mprepare_knowledge_graph_data\u001b[0;34m(ontology_file, use_multi_relation)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(model_file):\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  Training completion model...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 20\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_ontology_embeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m        \u001b[49m\u001b[43mowl_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43montology_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_output\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgcn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# GCN good for structural tasks\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m        \u001b[49m\u001b[43mout_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m150\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_fn_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcosine\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Triplet loss for relation learning\u001b[39;49;00m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtext_model_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall-MiniLM-L6-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Generate embeddings\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(embedding_file):\n",
      "\u001b[0;31mTypeError\u001b[0m: train_ontology_embeddings() got an unexpected keyword argument 'text_model_name'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def prepare_knowledge_graph_data(ontology_file, use_multi_relation=True):\n",
    "    \"\"\"Prepare knowledge graph structure and embeddings for completion.\"\"\"\n",
    "    \n",
    "    if not os.path.exists(ontology_file):\n",
    "        print(f\"âŒ Ontology file not found: {ontology_file}\")\n",
    "        return None\n",
    "    \n",
    "    base_name = Path(ontology_file).stem\n",
    "    model_file = f\"{base_name}_completion_model.pt\"\n",
    "    embedding_file = f\"{base_name}_completion_embeddings.parquet\"\n",
    "    \n",
    "    print(f\"ðŸ”„ Preparing knowledge graph data for {ontology_file}...\")\n",
    "    \n",
    "    # Train model optimized for completion tasks\n",
    "    if not os.path.exists(model_file):\n",
    "        print(f\"  Training completion model...\")\n",
    "        result = train_ontology_embeddings(\n",
    "            owl_file=ontology_file,\n",
    "            model_output=model_file,\n",
    "            model_type=\"gcn\",  # GCN good for structural tasks\n",
    "            hidden_dim=256,\n",
    "            out_dim=128,\n",
    "            epochs=150,\n",
    "            loss_fn_name=\"cosine\",  # Triplet loss for relation learning\n",
    "            learning_rate=0.01,\n",
    "            text_model_name=\"all-MiniLM-L6-v2\"\n",
    "        )\n",
    "    \n",
    "    # Generate embeddings\n",
    "    if not os.path.exists(embedding_file):\n",
    "        print(f\"  Generating embeddings...\")\n",
    "        embed_result = embed_ontology_with_model(\n",
    "            model_path=model_file,\n",
    "            owl_file=ontology_file,\n",
    "            output_file=embedding_file\n",
    "        )\n",
    "    \n",
    "    # Load embeddings\n",
    "    df, metadata = load_embeddings_as_dataframe(embedding_file, return_metadata=True)\n",
    "    embeddings = np.stack(df['embedding'].to_numpy())\n",
    "    node_ids = df['node_id'].to_numpy()\n",
    "    \n",
    "    # Build graph structures\n",
    "    print(f\"  Building graph structures...\")\n",
    "    \n",
    "    # Basic subclass graph\n",
    "    try:\n",
    "        x, edge_index, class_mapping = build_graph_from_owl(ontology_file)\n",
    "        subclass_graph = {\n",
    "            'edge_index': edge_index,\n",
    "            'class_mapping': class_mapping\n",
    "        }\n",
    "        print(f\"    Subclass graph: {edge_index.shape[1]} edges\")\n",
    "    except Exception as e:\n",
    "        print(f\"    Failed to build subclass graph: {e}\")\n",
    "        subclass_graph = None\n",
    "    \n",
    "    # Multi-relation graph\n",
    "    multi_relation_graph = None\n",
    "    if use_multi_relation:\n",
    "        try:\n",
    "            multi_data = build_multi_relation_graph_from_owl(ontology_file)\n",
    "            multi_relation_graph = multi_data\n",
    "            print(f\"    Multi-relation graph: {multi_data['edge_index'].shape[1]} edges, {len(multi_data['relation_names'])} relation types\")\n",
    "        except Exception as e:\n",
    "            print(f\"    Failed to build multi-relation graph: {e}\")\n",
    "    \n",
    "    # Create NetworkX graph for analysis\n",
    "    nx_graph = nx.DiGraph()\n",
    "    if subclass_graph:\n",
    "        for i in range(subclass_graph['edge_index'].shape[1]):\n",
    "            src = int(subclass_graph['edge_index'][0, i])\n",
    "            dst = int(subclass_graph['edge_index'][1, i])\n",
    "            nx_graph.add_edge(src, dst, relation='subClassOf')\n",
    "    \n",
    "    return {\n",
    "        'ontology_file': ontology_file,\n",
    "        'embeddings': embeddings,\n",
    "        'node_ids': node_ids,\n",
    "        'df': df,\n",
    "        'metadata': metadata,\n",
    "        'subclass_graph': subclass_graph,\n",
    "        'multi_relation_graph': multi_relation_graph,\n",
    "        'nx_graph': nx_graph,\n",
    "        'id_to_idx': {node_id: idx for idx, node_id in enumerate(node_ids)},\n",
    "        'model_file': model_file,\n",
    "        'embedding_file': embedding_file\n",
    "    }\n",
    "\n",
    "# Prepare data\n",
    "ontology_files = ['EDAM.owl', 'cvdo.owl']  # Try available ontologies\n",
    "kg_data = None\n",
    "\n",
    "for ont_file in ontology_files:\n",
    "    if os.path.exists(ont_file):\n",
    "        kg_data = prepare_knowledge_graph_data(ont_file)\n",
    "        if kg_data:\n",
    "            print(f\"\\nâœ… Knowledge graph ready:\")\n",
    "            print(f\"  â€¢ Ontology: {ont_file}\")\n",
    "            print(f\"  â€¢ Concepts: {len(kg_data['node_ids']):,}\")\n",
    "            print(f\"  â€¢ Embeddings: {kg_data['embeddings'].shape[1]}D\")\n",
    "            print(f\"  â€¢ Graph edges: {kg_data['nx_graph'].number_of_edges():,}\")\n",
    "            break\n",
    "\n",
    "if not kg_data:\n",
    "    print(\"âŒ No suitable ontology files found for knowledge completion demo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Knowledge Graph Completion System\n",
    "\n",
    "Build a comprehensive system for predicting missing relations and concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KnowledgeGraphCompleter:\n",
    "    def __init__(self, kg_data):\n",
    "        \"\"\"Initialize knowledge graph completion system.\"\"\"\n",
    "        self.kg_data = kg_data\n",
    "        self.embeddings = kg_data['embeddings']\n",
    "        self.node_ids = kg_data['node_ids']\n",
    "        self.id_to_idx = kg_data['id_to_idx']\n",
    "        self.graph = kg_data['nx_graph']\n",
    "        \n",
    "        # Pre-compute similarity matrix\n",
    "        print(f\"ðŸ”„ Computing similarity matrix for {len(self.node_ids)} concepts...\")\n",
    "        self.similarity_matrix = cosine_similarity(self.embeddings)\n",
    "        \n",
    "        # Extract concept names for readability\n",
    "        self.concept_names = [self._extract_name(node_id) for node_id in self.node_ids]\n",
    "        \n",
    "        print(f\"âœ… Knowledge graph completer ready!\")\n",
    "    \n",
    "    def _extract_name(self, node_id):\n",
    "        \"\"\"Extract readable name from IRI.\"\"\"\n",
    "        if '#' in node_id:\n",
    "            name = node_id.split('#')[-1]\n",
    "        else:\n",
    "            name = node_id.split('/')[-1]\n",
    "        return name.replace('_', ' ').replace('-', ' ')\n",
    "    \n",
    "    def predict_missing_subclass_relations(self, similarity_threshold=0.6, max_predictions=100):\n",
    "        \"\"\"Predict missing subclass relationships.\"\"\"\n",
    "        print(f\"ðŸ” Predicting missing subclass relations...\")\n",
    "        \n",
    "        predictions = []\n",
    "        existing_edges = set()\n",
    "        \n",
    "        # Build set of existing edges for fast lookup\n",
    "        if self.kg_data['subclass_graph']:\n",
    "            edge_index = self.kg_data['subclass_graph']['edge_index']\n",
    "            class_mapping = self.kg_data['subclass_graph']['class_mapping']\n",
    "            \n",
    "            # Map ontology indices to embedding indices\n",
    "            ont_to_emb_idx = {}\n",
    "            for ont_class, ont_idx in class_mapping.items():\n",
    "                class_iri = ont_class.iri if hasattr(ont_class, 'iri') else str(ont_class)\n",
    "                if class_iri in self.id_to_idx:\n",
    "                    ont_to_emb_idx[ont_idx] = self.id_to_idx[class_iri]\n",
    "            \n",
    "            # Convert existing edges to embedding index pairs\n",
    "            for i in range(edge_index.shape[1]):\n",
    "                src_ont = int(edge_index[0, i])\n",
    "                dst_ont = int(edge_index[1, i])\n",
    "                \n",
    "                if src_ont in ont_to_emb_idx and dst_ont in ont_to_emb_idx:\n",
    "                    src_emb = ont_to_emb_idx[src_ont]\n",
    "                    dst_emb = ont_to_emb_idx[dst_ont]\n",
    "                    existing_edges.add((src_emb, dst_emb))\n",
    "                    existing_edges.add((dst_emb, src_emb))  # Bidirectional for subclass\n",
    "        \n",
    "        print(f\"  Found {len(existing_edges)} existing relations\")\n",
    "        \n",
    "        # Find high-similarity pairs that aren't connected\n",
    "        n_concepts = len(self.node_ids)\n",
    "        \n",
    "        for i in range(n_concepts):\n",
    "            for j in range(i + 1, n_concepts):\n",
    "                if (i, j) not in existing_edges and (j, i) not in existing_edges:\n",
    "                    similarity = self.similarity_matrix[i, j]\n",
    "                    \n",
    "                    if similarity >= similarity_threshold:\n",
    "                        # Determine direction based on embedding characteristics\n",
    "                        emb_i = self.embeddings[i]\n",
    "                        emb_j = self.embeddings[j]\n",
    "                        \n",
    "                        norm_i = np.linalg.norm(emb_i)\n",
    "                        norm_j = np.linalg.norm(emb_j)\n",
    "                        \n",
    "                        # Heuristic: concepts with higher norms tend to be more general\n",
    "                        if norm_i > norm_j * 1.1:\n",
    "                            parent_idx, child_idx = i, j\n",
    "                            relation_type = 'parent_child'\n",
    "                        elif norm_j > norm_i * 1.1:\n",
    "                            parent_idx, child_idx = j, i\n",
    "                            relation_type = 'parent_child'\n",
    "                        else:\n",
    "                            parent_idx, child_idx = i, j\n",
    "                            relation_type = 'sibling'\n",
    "                        \n",
    "                        predictions.append({\n",
    "                            'parent_id': self.node_ids[parent_idx],\n",
    "                            'child_id': self.node_ids[child_idx],\n",
    "                            'parent_name': self.concept_names[parent_idx],\n",
    "                            'child_name': self.concept_names[child_idx],\n",
    "                            'similarity': float(similarity),\n",
    "                            'relation_type': relation_type,\n",
    "                            'confidence': self._calculate_relation_confidence(parent_idx, child_idx, similarity),\n",
    "                            'prediction_type': 'subclass'\n",
    "                        })\n",
    "        \n",
    "        # Sort by similarity and return top predictions\n",
    "        predictions.sort(key=lambda x: x['similarity'], reverse=True)\n",
    "        top_predictions = predictions[:max_predictions]\n",
    "        \n",
    "        print(f\"  Generated {len(top_predictions)} subclass predictions\")\n",
    "        return top_predictions\n",
    "    \n",
    "    def predict_semantic_relations(self, relation_types=['related_to', 'part_of', 'has_function'], \n",
    "                                  similarity_threshold=0.5, max_predictions=50):\n",
    "        \"\"\"Predict semantic relations beyond subclass hierarchy.\"\"\"\n",
    "        print(f\"ðŸ”— Predicting semantic relations...\")\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        # Use clustering to identify semantic groups\n",
    "        from sklearn.cluster import DBSCAN\n",
    "        \n",
    "        # Cluster similar concepts\n",
    "        clustering = DBSCAN(eps=0.3, min_samples=3, metric='cosine')\n",
    "        cluster_labels = clustering.fit_predict(self.embeddings)\n",
    "        \n",
    "        # Group concepts by cluster\n",
    "        clusters = {}\n",
    "        for idx, label in enumerate(cluster_labels):\n",
    "            if label != -1:  # Ignore noise points\n",
    "                if label not in clusters:\n",
    "                    clusters[label] = []\n",
    "                clusters[label].append(idx)\n",
    "        \n",
    "        print(f\"  Found {len(clusters)} semantic clusters\")\n",
    "        \n",
    "        # Predict relations within and between clusters\n",
    "        for cluster_id, concept_indices in clusters.items():\n",
    "            if len(concept_indices) < 2:\n",
    "                continue\n",
    "            \n",
    "            # Intra-cluster relations (concepts in same semantic space)\n",
    "            for i in range(len(concept_indices)):\n",
    "                for j in range(i + 1, len(concept_indices)):\n",
    "                    idx_i = concept_indices[i]\n",
    "                    idx_j = concept_indices[j]\n",
    "                    \n",
    "                    similarity = self.similarity_matrix[idx_i, idx_j]\n",
    "                    \n",
    "                    if similarity >= similarity_threshold:\n",
    "                        # Predict relation type based on concept characteristics\n",
    "                        predicted_relation = self._predict_relation_type(\n",
    "                            idx_i, idx_j, similarity, relation_types\n",
    "                        )\n",
    "                        \n",
    "                        if predicted_relation:\n",
    "                            predictions.append({\n",
    "                                'source_id': self.node_ids[idx_i],\n",
    "                                'target_id': self.node_ids[idx_j],\n",
    "                                'source_name': self.concept_names[idx_i],\n",
    "                                'target_name': self.concept_names[idx_j],\n",
    "                                'relation_type': predicted_relation['type'],\n",
    "                                'similarity': float(similarity),\n",
    "                                'confidence': predicted_relation['confidence'],\n",
    "                                'prediction_type': 'semantic_relation',\n",
    "                                'cluster_id': cluster_id\n",
    "                            })\n",
    "        \n",
    "        # Sort and return top predictions\n",
    "        predictions.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        top_predictions = predictions[:max_predictions]\n",
    "        \n",
    "        print(f\"  Generated {len(top_predictions)} semantic relation predictions\")\n",
    "        return top_predictions\n",
    "    \n",
    "    def _predict_relation_type(self, idx_i, idx_j, similarity, relation_types):\n",
    "        \"\"\"Predict the type of relation between two concepts.\"\"\"\n",
    "        name_i = self.concept_names[idx_i].lower()\n",
    "        name_j = self.concept_names[idx_j].lower()\n",
    "        \n",
    "        # Simple heuristics based on concept names\n",
    "        if 'function' in name_i or 'function' in name_j:\n",
    "            if 'has_function' in relation_types:\n",
    "                return {'type': 'has_function', 'confidence': similarity * 0.8}\n",
    "        \n",
    "        if any(word in name_i or word in name_j for word in ['part', 'component', 'element']):\n",
    "            if 'part_of' in relation_types:\n",
    "                return {'type': 'part_of', 'confidence': similarity * 0.7}\n",
    "        \n",
    "        # Default to related_to for high similarity\n",
    "        if 'related_to' in relation_types and similarity > 0.6:\n",
    "            return {'type': 'related_to', 'confidence': similarity * 0.6}\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def suggest_missing_concepts(self, embedding_gap_threshold=0.4, max_suggestions=20):\n",
    "        \"\"\"Suggest concepts that might be missing from the ontology.\"\"\"\n",
    "        print(f\"ðŸ’¡ Suggesting missing concepts...\")\n",
    "        \n",
    "        suggestions = []\n",
    "        \n",
    "        # Find gaps in embedding space using clustering\n",
    "        from sklearn.cluster import KMeans\n",
    "        \n",
    "        # Cluster embeddings to find dense regions\n",
    "        n_clusters = min(50, len(self.embeddings) // 10)  # Adaptive cluster count\n",
    "        kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(self.embeddings)\n",
    "        cluster_centers = kmeans.cluster_centers_\n",
    "        \n",
    "        # Find cluster centers that are far from existing concepts\n",
    "        for cluster_id, center in enumerate(cluster_centers):\n",
    "            # Find closest existing concept to this cluster center\n",
    "            similarities_to_center = cosine_similarity(\n",
    "                center.reshape(1, -1), \n",
    "                self.embeddings\n",
    "            )[0]\n",
    "            \n",
    "            max_similarity = np.max(similarities_to_center)\n",
    "            closest_concept_idx = np.argmax(similarities_to_center)\n",
    "            \n",
    "            # If no concept is very close to the center, suggest it as a gap\n",
    "            if max_similarity < embedding_gap_threshold:\n",
    "                # Find concepts in this cluster\n",
    "                cluster_concept_indices = np.where(cluster_labels == cluster_id)[0]\n",
    "                \n",
    "                if len(cluster_concept_indices) >= 3:  # Only suggest for non-trivial clusters\n",
    "                    cluster_concepts = [self.concept_names[i] for i in cluster_concept_indices[:5]]\n",
    "                    \n",
    "                    suggestions.append({\n",
    "                        'cluster_id': cluster_id,\n",
    "                        'gap_score': 1 - max_similarity,  # Higher gap = more potential\n",
    "                        'cluster_size': len(cluster_concept_indices),\n",
    "                        'closest_concept': self.concept_names[closest_concept_idx],\n",
    "                        'closest_similarity': float(max_similarity),\n",
    "                        'representative_concepts': cluster_concepts,\n",
    "                        'suggested_concept_area': self._suggest_concept_area(cluster_concepts),\n",
    "                        'prediction_type': 'missing_concept'\n",
    "                    })\n",
    "        \n",
    "        # Sort by gap score and return top suggestions\n",
    "        suggestions.sort(key=lambda x: x['gap_score'], reverse=True)\n",
    "        top_suggestions = suggestions[:max_suggestions]\n",
    "        \n",
    "        print(f\"  Generated {len(top_suggestions)} missing concept suggestions\")\n",
    "        return top_suggestions\n",
    "    \n",
    "    def _suggest_concept_area(self, concept_names):\n",
    "        \"\"\"Suggest what type of concept might be missing based on cluster.\"\"\"\n",
    "        # Simple heuristic based on common words\n",
    "        all_words = ' '.join(concept_names).lower()\n",
    "        \n",
    "        if 'data' in all_words or 'format' in all_words:\n",
    "            return 'data format or structure'\n",
    "        elif 'protein' in all_words or 'gene' in all_words:\n",
    "            return 'biological entity'\n",
    "        elif 'analysis' in all_words or 'method' in all_words:\n",
    "            return 'computational method'\n",
    "        elif 'disease' in all_words or 'disorder' in all_words:\n",
    "            return 'medical condition'\n",
    "        else:\n",
    "            return 'general concept'\n",
    "    \n",
    "    def _calculate_relation_confidence(self, idx_i, idx_j, similarity):\n",
    "        \"\"\"Calculate confidence score for predicted relation.\"\"\"\n",
    "        base_confidence = similarity\n",
    "        \n",
    "        # Boost confidence if concepts have similar neighbors\n",
    "        neighbors_i = np.argsort(self.similarity_matrix[idx_i])[-10:]  # Top 10 similar\n",
    "        neighbors_j = np.argsort(self.similarity_matrix[idx_j])[-10:]\n",
    "        \n",
    "        neighbor_overlap = len(set(neighbors_i).intersection(set(neighbors_j)))\n",
    "        neighborhood_bonus = (neighbor_overlap / 10) * 0.2\n",
    "        \n",
    "        return min(1.0, base_confidence + neighborhood_bonus)\n",
    "    \n",
    "    def validate_predictions(self, predictions, validation_method='cross_validation'):\n",
    "        \"\"\"Validate predictions using various methods.\"\"\"\n",
    "        print(f\"âœ… Validating {len(predictions)} predictions...\")\n",
    "        \n",
    "        validated_predictions = []\n",
    "        \n",
    "        if validation_method == 'cross_validation':\n",
    "            # Use existing relations to train a classifier\n",
    "            # This is a simplified validation - in practice you'd use held-out test data\n",
    "            \n",
    "            for pred in predictions:\n",
    "                # Simple validation based on embedding similarity and structure\n",
    "                validation_score = self._simple_validation(pred)\n",
    "                pred['validation_score'] = validation_score\n",
    "                pred['is_validated'] = validation_score > 0.6\n",
    "                validated_predictions.append(pred)\n",
    "        \n",
    "        validated_count = sum(1 for p in validated_predictions if p['is_validated'])\n",
    "        print(f\"  âœ“ {validated_count}/{len(predictions)} predictions validated\")\n",
    "        \n",
    "        return validated_predictions\n",
    "    \n",
    "    def _simple_validation(self, prediction):\n",
    "        \"\"\"Simple validation score based on embedding properties.\"\"\"\n",
    "        # This is a placeholder - real validation would use ground truth data\n",
    "        base_score = prediction.get('similarity', prediction.get('confidence', 0.5))\n",
    "        \n",
    "        # Penalize very high similarities (might be too obvious/already known)\n",
    "        if base_score > 0.95:\n",
    "            base_score *= 0.8\n",
    "        \n",
    "        # Boost medium-high similarities (good predictions)\n",
    "        if 0.7 <= base_score <= 0.9:\n",
    "            base_score *= 1.1\n",
    "        \n",
    "        return min(1.0, base_score)\n",
    "\n",
    "# Initialize completer\n",
    "if kg_data:\n",
    "    completer = KnowledgeGraphCompleter(kg_data)\n",
    "    print(\"\\nðŸš€ Knowledge graph completion system ready!\")\n",
    "else:\n",
    "    print(\"Cannot initialize completer without knowledge graph data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Generate Knowledge Completion Predictions\n",
    "\n",
    "Generate different types of completion predictions and analyze their quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate completion predictions\n",
    "if 'completer' in locals():\n",
    "    print(\"ðŸ” GENERATING KNOWLEDGE COMPLETION PREDICTIONS\")\n",
    "    print(\"=\" * 55)\n",
    "    \n",
    "    # 1. Predict missing subclass relations\n",
    "    subclass_predictions = completer.predict_missing_subclass_relations(\n",
    "        similarity_threshold=0.7,\n",
    "        max_predictions=30\n",
    "    )\n",
    "    \n",
    "    # 2. Predict semantic relations\n",
    "    semantic_predictions = completer.predict_semantic_relations(\n",
    "        relation_types=['related_to', 'part_of', 'has_function'],\n",
    "        similarity_threshold=0.6,\n",
    "        max_predictions=25\n",
    "    )\n",
    "    \n",
    "    # 3. Suggest missing concepts\n",
    "    concept_suggestions = completer.suggest_missing_concepts(\n",
    "        embedding_gap_threshold=0.5,\n",
    "        max_suggestions=15\n",
    "    )\n",
    "    \n",
    "    # Combine all predictions\n",
    "    all_predictions = subclass_predictions + semantic_predictions\n",
    "    \n",
    "    print(f\"\\nðŸ“Š COMPLETION SUMMARY:\")\n",
    "    print(f\"  â€¢ Subclass relations: {len(subclass_predictions)}\")\n",
    "    print(f\"  â€¢ Semantic relations: {len(semantic_predictions)}\")\n",
    "    print(f\"  â€¢ Missing concepts: {len(concept_suggestions)}\")\n",
    "    print(f\"  â€¢ Total predictions: {len(all_predictions)}\")\n",
    "    \n",
    "    # Show top predictions\n",
    "    if subclass_predictions:\n",
    "        print(f\"\\nðŸ† TOP SUBCLASS RELATION PREDICTIONS:\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, pred in enumerate(subclass_predictions[:10]):\n",
    "            rel_symbol = \"âŠ†\" if pred['relation_type'] == 'parent_child' else \"â‰ˆ\"\n",
    "            conf_color = \"ðŸŸ¢\" if pred['confidence'] > 0.8 else \"ðŸŸ¡\" if pred['confidence'] > 0.6 else \"ðŸ”´\"\n",
    "            print(f\"{conf_color} {i+1:2d}. {pred['child_name'][:25]:25} {rel_symbol} {pred['parent_name'][:25]:25} ({pred['similarity']:.3f})\")\n",
    "    \n",
    "    if semantic_predictions:\n",
    "        print(f\"\\nðŸ”— TOP SEMANTIC RELATION PREDICTIONS:\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, pred in enumerate(semantic_predictions[:10]):\n",
    "            rel_symbols = {'related_to': 'â†”', 'part_of': 'âŠ‚', 'has_function': 'â†’'}\n",
    "            rel_symbol = rel_symbols.get(pred['relation_type'], '?')\n",
    "            conf_color = \"ðŸŸ¢\" if pred['confidence'] > 0.8 else \"ðŸŸ¡\" if pred['confidence'] > 0.6 else \"ðŸ”´\"\n",
    "            print(f\"{conf_color} {i+1:2d}. {pred['source_name'][:20]:20} {rel_symbol} {pred['target_name'][:20]:20} [{pred['relation_type']}] ({pred['confidence']:.3f})\")\n",
    "    \n",
    "    if concept_suggestions:\n",
    "        print(f\"\\nðŸ’¡ TOP MISSING CONCEPT SUGGESTIONS:\")\n",
    "        print(\"-\" * 70)\n",
    "        for i, sugg in enumerate(concept_suggestions[:8]):\n",
    "            gap_color = \"ðŸ”´\" if sugg['gap_score'] > 0.7 else \"ðŸŸ¡\" if sugg['gap_score'] > 0.5 else \"ðŸŸ¢\"\n",
    "            print(f\"{gap_color} {i+1:2d}. {sugg['suggested_concept_area']:25} (gap: {sugg['gap_score']:.3f}, size: {sugg['cluster_size']})\")\n",
    "            print(f\"     Examples: {', '.join(sugg['representative_concepts'][:3])}\")\n",
    "            print()\n",
    "    \n",
    "else:\n",
    "    print(\"Completer not available - please run previous cells first\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Validate and Score Predictions\n",
    "\n",
    "Apply validation techniques to assess prediction quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validate predictions\n",
    "if 'all_predictions' in locals() and all_predictions:\n",
    "    print(\"âœ… VALIDATING COMPLETION PREDICTIONS\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Validate all predictions\n",
    "    validated_predictions = completer.validate_predictions(\n",
    "        all_predictions,\n",
    "        validation_method='cross_validation'\n",
    "    )\n",
    "    \n",
    "    # Analyze validation results\n",
    "    val_df = pd.DataFrame(validated_predictions)\n",
    "    \n",
    "    print(f\"\\nðŸ“ˆ VALIDATION ANALYSIS:\")\n",
    "    print(f\"  â€¢ Total predictions: {len(validated_predictions)}\")\n",
    "    print(f\"  â€¢ Validated predictions: {val_df['is_validated'].sum()}\")\n",
    "    print(f\"  â€¢ Validation rate: {val_df['is_validated'].mean()*100:.1f}%\")\n",
    "    print(f\"  â€¢ Mean validation score: {val_df['validation_score'].mean():.3f}\")\n",
    "    \n",
    "    # Validation by prediction type\n",
    "    print(f\"\\nðŸ“Š VALIDATION BY TYPE:\")\n",
    "    type_validation = val_df.groupby('prediction_type').agg({\n",
    "        'is_validated': ['count', 'sum', 'mean'],\n",
    "        'validation_score': 'mean'\n",
    "    }).round(3)\n",
    "    \n",
    "    for pred_type in val_df['prediction_type'].unique():\n",
    "        subset = val_df[val_df['prediction_type'] == pred_type]\n",
    "        validated_count = subset['is_validated'].sum()\n",
    "        total_count = len(subset)\n",
    "        validation_rate = subset['is_validated'].mean() * 100\n",
    "        mean_score = subset['validation_score'].mean()\n",
    "        \n",
    "        print(f\"  â€¢ {pred_type:15}: {validated_count:2d}/{total_count:2d} ({validation_rate:4.1f}%) - score: {mean_score:.3f}\")\n",
    "    \n",
    "    # Create validation visualization\n",
    "    fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # Validation score distribution\n",
    "    ax1.hist(val_df['validation_score'], bins=20, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    ax1.axvline(val_df['validation_score'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {val_df[\"validation_score\"].mean():.3f}')\n",
    "    ax1.set_title('Validation Score Distribution')\n",
    "    ax1.set_xlabel('Validation Score')\n",
    "    ax1.set_ylabel('Frequency')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Validation by prediction type\n",
    "    type_counts = val_df.groupby(['prediction_type', 'is_validated']).size().unstack(fill_value=0)\n",
    "    type_counts.plot(kind='bar', ax=ax2, color=['lightcoral', 'lightgreen'])\n",
    "    ax2.set_title('Validation Results by Prediction Type')\n",
    "    ax2.set_xlabel('Prediction Type')\n",
    "    ax2.set_ylabel('Count')\n",
    "    ax2.legend(['Not Validated', 'Validated'])\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Confidence vs Validation Score scatter\n",
    "    confidence_col = 'confidence' if 'confidence' in val_df.columns else 'similarity'\n",
    "    if confidence_col in val_df.columns:\n",
    "        colors = ['red' if not v else 'green' for v in val_df['is_validated']]\n",
    "        scatter = ax3.scatter(val_df[confidence_col], val_df['validation_score'], \n",
    "                            c=colors, alpha=0.6)\n",
    "        ax3.set_title(f'{confidence_col.title()} vs Validation Score')\n",
    "        ax3.set_xlabel(f'{confidence_col.title()}')\n",
    "        ax3.set_ylabel('Validation Score')\n",
    "        ax3.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Add correlation line\n",
    "        z = np.polyfit(val_df[confidence_col], val_df['validation_score'], 1)\n",
    "        p = np.poly1d(z)\n",
    "        ax3.plot(val_df[confidence_col].sort_values(), p(val_df[confidence_col].sort_values()), \"b--\", alpha=0.8)\n",
    "    \n",
    "    # Top validated predictions\n",
    "    top_validated = val_df[val_df['is_validated']].nlargest(10, 'validation_score')\n",
    "    if not top_validated.empty:\n",
    "        y_pos = np.arange(len(top_validated))\n",
    "        \n",
    "        if 'source_name' in top_validated.columns:\n",
    "            labels = [f\"{row['source_name']} â†’ {row['target_name']}\" \n",
    "                     for _, row in top_validated.iterrows()]\n",
    "        else:\n",
    "            labels = [f\"{row['child_name']} âŠ† {row['parent_name']}\" \n",
    "                     for _, row in top_validated.iterrows()]\n",
    "        \n",
    "        ax4.barh(y_pos, top_validated['validation_score'], color='gold')\n",
    "        ax4.set_yticks(y_pos)\n",
    "        ax4.set_yticklabels(labels, fontsize=8)\n",
    "        ax4.set_title('Top 10 Validated Predictions')\n",
    "        ax4.set_xlabel('Validation Score')\n",
    "        ax4.grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"No predictions available for validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Knowledge Graph Expansion Visualization\n",
    "\n",
    "Visualize how the knowledge graph would expand with predicted completions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_expansion_visualization(completer, predictions, max_nodes=50):\n",
    "    \"\"\"Create interactive visualization of knowledge graph expansion.\"\"\"\n",
    "    \n",
    "    if not predictions:\n",
    "        print(\"No predictions to visualize\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"ðŸŽ¨ Creating knowledge graph expansion visualization...\")\n",
    "    \n",
    "    # Select top predictions for visualization\n",
    "    top_predictions = predictions[:max_nodes//2]  # Limit for readability\n",
    "    \n",
    "    # Build expanded graph\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Track node types\n",
    "    node_types = {}  # 'existing', 'predicted_relation', 'suggested_concept'\n",
    "    edge_types = {}  # 'existing', 'predicted'\n",
    "    prediction_scores = {}\n",
    "    \n",
    "    # Add existing nodes and edges from a sample of the original graph\n",
    "    existing_nodes = set()\n",
    "    sample_size = min(30, len(completer.node_ids))  # Sample for visualization\n",
    "    sample_indices = np.random.choice(len(completer.node_ids), sample_size, replace=False)\n",
    "    \n",
    "    for idx in sample_indices:\n",
    "        node_id = f\"existing_{idx}\"\n",
    "        concept_name = completer.concept_names[idx]\n",
    "        G.add_node(node_id, \n",
    "                  name=concept_name, \n",
    "                  full_id=completer.node_ids[idx],\n",
    "                  type='existing')\n",
    "        existing_nodes.add(node_id)\n",
    "        node_types[node_id] = 'existing'\n",
    "    \n",
    "    # Add some existing edges\n",
    "    existing_edges = list(completer.graph.edges())[:20]  # Sample existing edges\n",
    "    for src, dst in existing_edges:\n",
    "        src_node = f\"existing_{src}\"\n",
    "        dst_node = f\"existing_{dst}\"\n",
    "        \n",
    "        if src_node in existing_nodes and dst_node in existing_nodes:\n",
    "            G.add_edge(src_node, dst_node, type='existing', relation='subClassOf')\n",
    "            edge_types[(src_node, dst_node)] = 'existing'\n",
    "    \n",
    "    # Add predicted relations\n",
    "    for i, pred in enumerate(top_predictions):\n",
    "        if pred['prediction_type'] in ['subclass', 'semantic_relation']:\n",
    "            # Create node IDs for prediction\n",
    "            if pred['prediction_type'] == 'subclass':\n",
    "                src_node = f\"pred_src_{i}\"\n",
    "                dst_node = f\"pred_dst_{i}\"\n",
    "                src_name = pred['child_name']\n",
    "                dst_name = pred['parent_name']\n",
    "                relation = pred['relation_type']\n",
    "            else:  # semantic_relation\n",
    "                src_node = f\"pred_src_{i}\"\n",
    "                dst_node = f\"pred_dst_{i}\"\n",
    "                src_name = pred['source_name']\n",
    "                dst_name = pred['target_name']\n",
    "                relation = pred['relation_type']\n",
    "            \n",
    "            # Add nodes\n",
    "            G.add_node(src_node, name=src_name, type='predicted_concept', full_id=pred.get('child_id', pred.get('source_id', '')))\n",
    "            G.add_node(dst_node, name=dst_name, type='predicted_concept', full_id=pred.get('parent_id', pred.get('target_id', '')))\n",
    "            \n",
    "            node_types[src_node] = 'predicted_relation'\n",
    "            node_types[dst_node] = 'predicted_relation'\n",
    "            \n",
    "            # Add edge\n",
    "            score = pred.get('similarity', pred.get('confidence', 0.5))\n",
    "            G.add_edge(src_node, dst_node, \n",
    "                      type='predicted', \n",
    "                      relation=relation,\n",
    "                      score=score)\n",
    "            edge_types[(src_node, dst_node)] = 'predicted'\n",
    "            prediction_scores[(src_node, dst_node)] = score\n",
    "    \n",
    "    print(f\"  Graph: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")\n",
    "    \n",
    "    # Layout the graph\n",
    "    pos = nx.spring_layout(G, k=3, iterations=50, seed=42)\n",
    "    \n",
    "    # Create plotly traces\n",
    "    \n",
    "    # Edge traces\n",
    "    existing_edge_x, existing_edge_y = [], []\n",
    "    predicted_edge_x, predicted_edge_y = [], []\n",
    "    \n",
    "    for edge in G.edges():\n",
    "        x0, y0 = pos[edge[0]]\n",
    "        x1, y1 = pos[edge[1]]\n",
    "        \n",
    "        if edge_types.get(edge, 'predicted') == 'existing':\n",
    "            existing_edge_x.extend([x0, x1, None])\n",
    "            existing_edge_y.extend([y0, y1, None])\n",
    "        else:\n",
    "            predicted_edge_x.extend([x0, x1, None])\n",
    "            predicted_edge_y.extend([y0, y1, None])\n",
    "    \n",
    "    existing_edge_trace = go.Scatter(\n",
    "        x=existing_edge_x, y=existing_edge_y,\n",
    "        line=dict(width=1, color='#888'),\n",
    "        hoverinfo='none',\n",
    "        mode='lines',\n",
    "        name='Existing Relations'\n",
    "    )\n",
    "    \n",
    "    predicted_edge_trace = go.Scatter(\n",
    "        x=predicted_edge_x, y=predicted_edge_y,\n",
    "        line=dict(width=2, color='red', dash='dash'),\n",
    "        hoverinfo='none',\n",
    "        mode='lines',\n",
    "        name='Predicted Relations'\n",
    "    )\n",
    "    \n",
    "    # Node traces\n",
    "    existing_nodes_x = [pos[node][0] for node in G.nodes() if node_types.get(node, '') == 'existing']\n",
    "    existing_nodes_y = [pos[node][1] for node in G.nodes() if node_types.get(node, '') == 'existing']\n",
    "    existing_text = [G.nodes[node]['name'] for node in G.nodes() if node_types.get(node, '') == 'existing']\n",
    "    \n",
    "    predicted_nodes_x = [pos[node][0] for node in G.nodes() if node_types.get(node, '') == 'predicted_relation']\n",
    "    predicted_nodes_y = [pos[node][1] for node in G.nodes() if node_types.get(node, '') == 'predicted_relation']\n",
    "    predicted_text = [G.nodes[node]['name'] for node in G.nodes() if node_types.get(node, '') == 'predicted_relation']\n",
    "    \n",
    "    existing_node_trace = go.Scatter(\n",
    "        x=existing_nodes_x, y=existing_nodes_y,\n",
    "        mode='markers+text',\n",
    "        text=existing_text,\n",
    "        textposition=\"middle center\",\n",
    "        name='Existing Concepts',\n",
    "        marker=dict(\n",
    "            size=15,\n",
    "            color='lightblue',\n",
    "            line=dict(width=1, color='blue')\n",
    "        ),\n",
    "        hovertemplate='<b>%{text}</b><br>Type: Existing Concept<extra></extra>'\n",
    "    )\n",
    "    \n",
    "    predicted_node_trace = go.Scatter(\n",
    "        x=predicted_nodes_x, y=predicted_nodes_y,\n",
    "        mode='markers+text',\n",
    "        text=predicted_text,\n",
    "        textposition=\"middle center\",\n",
    "        name='Predicted Concepts',\n",
    "        marker=dict(\n",
    "            size=18,\n",
    "            color='lightcoral',\n",
    "            line=dict(width=2, color='red')\n",
    "        ),\n",
    "        hovertemplate='<b>%{text}</b><br>Type: Predicted Concept<extra></extra>'\n",
    "    )\n",
    "    \n",
    "    # Create figure\n",
    "    fig = go.Figure(data=[existing_edge_trace, predicted_edge_trace, \n",
    "                         existing_node_trace, predicted_node_trace],\n",
    "                   layout=go.Layout(\n",
    "                        title='Knowledge Graph Expansion Preview<br><sub>Blue: Existing concepts, Red: Predicted additions, Dashed lines: Predicted relations</sub>',\n",
    "                        titlefont_size=16,\n",
    "                        showlegend=True,\n",
    "                        hovermode='closest',\n",
    "                        margin=dict(b=20,l=5,r=5,t=60),\n",
    "                        annotations=[ dict(\n",
    "                            text=f\"Showing {len(top_predictions)} top predictions from {len(predictions)} total\",\n",
    "                            showarrow=False,\n",
    "                            xref=\"paper\", yref=\"paper\",\n",
    "                            x=0.005, y=-0.002 ) ],\n",
    "                        xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        yaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "                        width=1200,\n",
    "                        height=800\n",
    "                   ))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "# Create expansion visualization\n",
    "if 'validated_predictions' in locals() and validated_predictions:\n",
    "    # Use only validated predictions for visualization\n",
    "    validated_only = [p for p in validated_predictions if p.get('is_validated', False)]\n",
    "    \n",
    "    if validated_only:\n",
    "        expansion_fig = create_expansion_visualization(\n",
    "            completer, validated_only, max_nodes=40\n",
    "        )\n",
    "        \n",
    "        if expansion_fig:\n",
    "            expansion_fig.show()\n",
    "    else:\n",
    "        print(\"No validated predictions available for visualization\")\n",
    "else:\n",
    "    print(\"No predictions available for expansion visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Export Completion Results\n",
    "\n",
    "Export completion predictions in formats suitable for ontology curation tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_completion_results(predictions, concept_suggestions, kg_data, output_dir='completion_results'):\n",
    "    \"\"\"Export completion results for ontology curation.\"\"\"\n",
    "    \n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    ontology_name = Path(kg_data['ontology_file']).stem\n",
    "    timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')\n",
    "    \n",
    "    exported_files = []\n",
    "    \n",
    "    print(f\"ðŸ“ Exporting completion results to {output_dir}/...\")\n",
    "    \n",
    "    # 1. Comprehensive CSV report\n",
    "    if predictions:\n",
    "        csv_file = Path(output_dir) / f\"{ontology_name}_completion_predictions_{timestamp}.csv\"\n",
    "        df = pd.DataFrame(predictions)\n",
    "        df.to_csv(csv_file, index=False)\n",
    "        exported_files.append(str(csv_file))\n",
    "        print(f\"  âœ“ Predictions CSV: {csv_file}\")\n",
    "    \n",
    "    # 2. OWL additions (for validated predictions)\n",
    "    validated_preds = [p for p in predictions if p.get('is_validated', False)]\n",
    "    if validated_preds:\n",
    "        owl_file = Path(output_dir) / f\"{ontology_name}_predicted_additions_{timestamp}.owl\"\n",
    "        \n",
    "        with open(owl_file, 'w') as f:\n",
    "            f.write('<?xml version=\"1.0\" encoding=\"UTF-8\"?>\\n')\n",
    "            f.write('<rdf:RDF xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\"\\n')\n",
    "            f.write('         xmlns:owl=\"http://www.w3.org/2002/07/owl#\"\\n')\n",
    "            f.write('         xmlns:rdfs=\"http://www.w3.org/2000/01/rdf-schema#\">\\n\\n')\n",
    "            f.write(f'<!-- Predicted additions for {ontology_name} -->\\n')\n",
    "            f.write(f'<!-- Generated by on2vec on {pd.Timestamp.now()} -->\\n\\n')\n",
    "            \n",
    "            for pred in validated_preds:\n",
    "                if pred['prediction_type'] == 'subclass':\n",
    "                    f.write(f'<!-- Predicted subclass relation: {pred[\"child_name\"]} âŠ† {pred[\"parent_name\"]} -->\\n')\n",
    "                    f.write(f'<owl:Class rdf:about=\"{pred[\"child_id\"]}\">\\n')\n",
    "                    f.write(f'  <rdfs:subClassOf rdf:resource=\"{pred[\"parent_id\"]}\"/>\\n')\n",
    "                    f.write(f'  <rdfs:comment>Predicted by on2vec with confidence {pred.get(\"confidence\", 0.5):.3f}</rdfs:comment>\\n')\n",
    "                    f.write(f'</owl:Class>\\n\\n')\n",
    "                \n",
    "                elif pred['prediction_type'] == 'semantic_relation':\n",
    "                    f.write(f'<!-- Predicted semantic relation: {pred[\"source_name\"]} {pred[\"relation_type\"]} {pred[\"target_name\"]} -->\\n')\n",
    "                    f.write(f'<owl:Class rdf:about=\"{pred[\"source_id\"]}\">\\n')\n",
    "                    f.write(f'  <!-- {pred[\"relation_type\"]} relation to {pred[\"target_id\"]} -->\\n')\n",
    "                    f.write(f'  <rdfs:comment>Predicted relation by on2vec with confidence {pred.get(\"confidence\", 0.5):.3f}</rdfs:comment>\\n')\n",
    "                    f.write(f'</owl:Class>\\n\\n')\n",
    "            \n",
    "            f.write('</rdf:RDF>\\n')\n",
    "        \n",
    "        exported_files.append(str(owl_file))\n",
    "        print(f\"  âœ“ OWL additions: {owl_file}\")\n",
    "    \n",
    "    # 3. Concept suggestions report\n",
    "    if concept_suggestions:\n",
    "        suggestions_file = Path(output_dir) / f\"{ontology_name}_concept_suggestions_{timestamp}.txt\"\n",
    "        \n",
    "        with open(suggestions_file, 'w') as f:\n",
    "            f.write(f\"MISSING CONCEPT SUGGESTIONS FOR {ontology_name.upper()}\\n\")\n",
    "            f.write(f\"{'='*60}\\n\\n\")\n",
    "            f.write(f\"Generated: {pd.Timestamp.now()}\\n\")\n",
    "            f.write(f\"Total suggestions: {len(concept_suggestions)}\\n\\n\")\n",
    "            \n",
    "            for i, sugg in enumerate(concept_suggestions, 1):\n",
    "                f.write(f\"{i:2d}. SUGGESTED CONCEPT AREA: {sugg['suggested_concept_area']}\\n\")\n",
    "                f.write(f\"    Gap Score: {sugg['gap_score']:.3f}\\n\")\n",
    "                f.write(f\"    Cluster Size: {sugg['cluster_size']} concepts\\n\")\n",
    "                f.write(f\"    Representative Concepts:\\n\")\n",
    "                for concept in sugg['representative_concepts']:\n",
    "                    f.write(f\"      - {concept}\\n\")\n",
    "                f.write(f\"    Closest Existing: {sugg['closest_concept']} (sim: {sugg['closest_similarity']:.3f})\\n\")\n",
    "                f.write(\"\\n\")\n",
    "        \n",
    "        exported_files.append(str(suggestions_file))\n",
    "        print(f\"  âœ“ Concept suggestions: {suggestions_file}\")\n",
    "    \n",
    "    # 4. Curator instructions\n",
    "    instructions_file = Path(output_dir) / f\"{ontology_name}_curation_instructions_{timestamp}.md\"\n",
    "    \n",
    "    with open(instructions_file, 'w') as f:\n",
    "        f.write(f\"# Ontology Curation Instructions: {ontology_name}\\n\\n\")\n",
    "        f.write(f\"Generated by on2vec on {pd.Timestamp.now()}\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Summary\\n\\n\")\n",
    "        f.write(f\"- **Total relation predictions**: {len([p for p in predictions if p['prediction_type'] in ['subclass', 'semantic_relation']])}\\n\")\n",
    "        f.write(f\"- **Validated predictions**: {len(validated_preds)}\\n\")\n",
    "        f.write(f\"- **Concept suggestions**: {len(concept_suggestions)}\\n\")\n",
    "        f.write(f\"- **Source ontology**: {kg_data['ontology_file']}\\n\\n\")\n",
    "        \n",
    "        f.write(\"## How to Use These Results\\n\\n\")\n",
    "        f.write(\"### 1. Review Relation Predictions\\n\")\n",
    "        f.write(\"- Check the CSV file for all predictions with confidence scores\\n\")\n",
    "        f.write(\"- Focus on validated predictions (is_validated = True)\\n\")\n",
    "        f.write(\"- High confidence (>0.8) predictions are most likely correct\\n\\n\")\n",
    "        \n",
    "        f.write(\"### 2. Import OWL Additions\\n\")\n",
    "        f.write(\"- The OWL file contains validated predictions in OWL format\\n\")\n",
    "        f.write(\"- Can be imported into ProtÃ©gÃ© or other ontology editors\\n\")\n",
    "        f.write(\"- Review each addition before accepting\\n\\n\")\n",
    "        \n",
    "        f.write(\"### 3. Consider Missing Concepts\\n\")\n",
    "        f.write(\"- Review concept suggestions for potential gaps\\n\")\n",
    "        f.write(\"- High gap scores indicate areas needing attention\\n\")\n",
    "        f.write(\"- Use representative concepts as inspiration for new additions\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Top Recommendations\\n\\n\")\n",
    "        \n",
    "        # Top 5 validated predictions\n",
    "        if validated_preds:\n",
    "            f.write(\"### Highest Confidence Predictions\\n\")\n",
    "            top_validated = sorted(validated_preds, key=lambda x: x.get('validation_score', 0), reverse=True)[:5]\n",
    "            for i, pred in enumerate(top_validated, 1):\n",
    "                if pred['prediction_type'] == 'subclass':\n",
    "                    f.write(f\"{i}. **{pred['child_name']}** âŠ† **{pred['parent_name']}** (score: {pred.get('validation_score', 0.5):.3f})\\n\")\n",
    "                else:\n",
    "                    f.write(f\"{i}. **{pred['source_name']}** {pred['relation_type']} **{pred['target_name']}** (score: {pred.get('validation_score', 0.5):.3f})\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        # Top concept suggestions\n",
    "        if concept_suggestions:\n",
    "            f.write(\"### Priority Missing Concepts\\n\")\n",
    "            for i, sugg in enumerate(concept_suggestions[:3], 1):\n",
    "                f.write(f\"{i}. **{sugg['suggested_concept_area']}** (gap: {sugg['gap_score']:.3f})\\n\")\n",
    "                f.write(f\"   - Examples: {', '.join(sugg['representative_concepts'][:3])}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        f.write(\"## Files Included\\n\\n\")\n",
    "        for file_path in exported_files:\n",
    "            f.write(f\"- `{Path(file_path).name}`\\n\")\n",
    "    \n",
    "    exported_files.append(str(instructions_file))\n",
    "    print(f\"  âœ“ Instructions: {instructions_file}\")\n",
    "    \n",
    "    # 5. JSON export for programmatic use\n",
    "    json_file = Path(output_dir) / f\"{ontology_name}_completion_results_{timestamp}.json\"\n",
    "    \n",
    "    completion_data = {\n",
    "        'metadata': {\n",
    "            'ontology_file': kg_data['ontology_file'],\n",
    "            'generation_timestamp': pd.Timestamp.now().isoformat(),\n",
    "            'tool': 'on2vec',\n",
    "            'total_predictions': len(predictions),\n",
    "            'validated_predictions': len(validated_preds),\n",
    "            'concept_suggestions': len(concept_suggestions)\n",
    "        },\n",
    "        'relation_predictions': predictions,\n",
    "        'concept_suggestions': concept_suggestions\n",
    "    }\n",
    "    \n",
    "    import json\n",
    "    with open(json_file, 'w') as f:\n",
    "        json.dump(completion_data, f, indent=2, default=str)\n",
    "    \n",
    "    exported_files.append(str(json_file))\n",
    "    print(f\"  âœ“ JSON: {json_file}\")\n",
    "    \n",
    "    print(f\"\\nâœ… Exported {len(exported_files)} files to {output_dir}/\")\n",
    "    return exported_files\n",
    "\n",
    "# Export results\n",
    "if 'validated_predictions' in locals() and 'concept_suggestions' in locals() and kg_data:\n",
    "    exported_files = export_completion_results(\n",
    "        validated_predictions,\n",
    "        concept_suggestions,\n",
    "        kg_data\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nðŸ“‹ Export Summary:\")\n",
    "    for file_path in exported_files:\n",
    "        file_size = Path(file_path).stat().st_size\n",
    "        print(f\"  â€¢ {Path(file_path).name}: {file_size:,} bytes\")\n",
    "        \n",
    "else:\n",
    "    print(\"No completion results available for export\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated comprehensive knowledge graph completion capabilities using on2vec embeddings:\n",
    "\n",
    "### âœ… Key Achievements:\n",
    "\n",
    "1. **Missing Relation Prediction**: Identified potential subclass and semantic relationships\n",
    "2. **Concept Gap Analysis**: Found areas where new concepts might be needed\n",
    "3. **Validation Framework**: Assessed prediction quality using multiple validation methods\n",
    "4. **Interactive Visualization**: Showed how the knowledge graph would expand\n",
    "5. **Curation-Ready Export**: Generated files in formats suitable for ontology editors\n",
    "6. **Quality Metrics**: Provided confidence scores and validation assessments\n",
    "\n",
    "### ðŸŽ¯ Practical Applications:\n",
    "\n",
    "- **Ontology Evolution**: Systematically identify and add missing knowledge\n",
    "- **Quality Assurance**: Find inconsistencies and gaps in existing ontologies\n",
    "- **Semi-Automated Curation**: Assist human curators with intelligent suggestions\n",
    "- **Cross-Domain Integration**: Bridge concepts from related knowledge domains\n",
    "- **Knowledge Discovery**: Uncover hidden relationships in large ontologies\n",
    "\n",
    "### ðŸ“Š Completion Types Demonstrated:\n",
    "\n",
    "1. **Subclass Relations**: Traditional hierarchical relationships\n",
    "2. **Semantic Relations**: Domain-specific properties like `part_of`, `has_function`\n",
    "3. **Missing Concepts**: Identification of conceptual gaps in the knowledge space\n",
    "4. **Relation Validation**: Quality assessment using embedding consistency\n",
    "\n",
    "### ðŸ”§ Technical Features:\n",
    "\n",
    "- **Multi-Modal Validation**: Combining embedding similarity with structural consistency\n",
    "- **Confidence Scoring**: Probabilistic assessment of prediction quality\n",
    "- **Scalable Processing**: Efficient similarity computation for large ontologies\n",
    "- **Export Integration**: Standard formats for ontology editing tools\n",
    "\n",
    "### ðŸš€ Next Steps:\n",
    "\n",
    "1. **Active Learning**: Use curator feedback to improve prediction models\n",
    "2. **Temporal Tracking**: Monitor ontology evolution and suggest updates\n",
    "3. **Domain Adaptation**: Fine-tune completion for specific knowledge domains\n",
    "4. **Collaborative Curation**: Build interfaces for distributed ontology development\n",
    "5. **Automated Testing**: Validate completions against gold standard benchmarks\n",
    "\n",
    "The knowledge graph completion capabilities shown here demonstrate how on2vec embeddings can accelerate ontology development and maintenance, helping curators build more complete and consistent knowledge resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
